AGE_YRS.1 + EDUC2.1 + GRADES.1,
dist = "negbin", na.action = na.omit, data = dat)
summary(zinb2)
summary(zinb2)
zinb2 <- zeroinfl(THIRTYDAYCIG.3 ~ STUDY_ARM + THIRTYDAYCIG.1 |
AGE_YRS.1 + EDUC2.1 + GRADES.1,
dist = "negbin", na.action = na.omit, data = dat)
summary(zinb2)
# Zero-inflated negative binomial
library(pscl)
zinb2 <- zeroinfl(THIRTYDAYCIG.3 ~ STUDY_ARM + THIRTYDAYCIG.1 |
AGE_YRS.1 + EDUC2.1 + GRADES.1,
dist = "negbin", na.action = na.omit, data = dat)
# Zero-inflated negative binomial
library(pscl)
zinb2 <- zeroinfl(THIRTYDAYCIG.3 ~ STUDY_ARM + THIRTYDAYCIG.1 |
AGE_YRS.1 + EDUC2.1 + GRADES.1,
dist = "negbin", na.action = na.omit, data = dat)
load("~/Desktop/Lab 8 my notes/Lab_08.Rdata")
table(dat$THIRTYDAYCIG.3)
table(dat$STUDY_ARM, dat$THIRTYDAYCIG.3)
by(dat$THIRTYDAYCIG.3, dat$STUDY_ARM, mean, na.rm = TRUE)
library(mice)
md.pattern(x = dat)
# Use t-test (Welch's version, not assuming equal
# group variances) for quantitative baseline variables.
t.test(x = dat$THIRTYDAYCIG.1[dat$STUDY_ARM == 0],
y = dat$THIRTYDAYCIG.1[dat$STUDY_ARM == 1],
alternative = "two.sided",
var.equal = FALSE)
library(car)
lm1 <- lm(THIRTYDAYCIG.3 ~ STUDY_ARM,
data = dat)
options(contrasts = c("contr.sum", "contr.poly"))
Anova(lm1, type = 3)
summary(lm1)
qqPlot(lm1) # Really bad!
cor(dat$THIRTYDAYCIG.1, dat$THIRTYDAYCIG.3, use = "complete.obs")
lm2 <- lm(THIRTYDAYCIG.3 ~ STUDY_ARM + THIRTYDAYCIG.1, data = dat)
Anova(lm2, type = 3)
summary(lm2)
qqPlot(lm2) # Really bad!
residualPlot(lm2) # Also bad!
mean(dat$THIRTYDAYCIG.3, na.rm = TRUE)
mean(dat$THIRTYDAYCIG.3, na.rm = TRUE)
mean(dat$THIRTYDAYCIG.3, na.rm = TRUE)
var(dat$THIRTYDAYCIG.3, na.rm = TRUE) # Yikes, big difference.
glm1 <- glm(THIRTYDAYCIG.3 ~ STUDY_ARM,
family = "poisson",
na.action = na.omit, data = dat)
summary(glm1)
glm2 <- glm(THIRTYDAYCIG.3 ~ STUDY_ARM + THIRTYDAYCIG.1,
family = "poisson",
na.action = na.omit, data = dat)
summary(glm2)
# Test for overdispersion. Null hypothesis is that Poisson
# assumption of equal mean and variance is true.
library(AER)
dispersiontest(glm1)
dispersiontest(glm2)
# Negative binomial model with no covariates.
library(MASS)
nb1 <- glm.nb(THIRTYDAYCIG.3 ~ STUDY_ARM,
na.action = na.omit, data = dat)
summary(nb1)
# Does the negative binomial model fit significantly better
# as measured by likelihood-ratio test? NOTE: this test will
# not run unless you delete missing data from the start as follows:
# dat <- na.omit(dat)
library(lmtest)
lrtest(glm1, nb1)
nb2 <- glm.nb(THIRTYDAYCIG.3 ~ STUDY_ARM + THIRTYDAYCIG.1,
control = glm.control(maxit = 1000),
na.action = na.omit, data = dat)
summary(nb2)
# Zero-inflated negative binomial
library(pscl)
zinb2 <- zeroinfl(THIRTYDAYCIG.3 ~ STUDY_ARM + THIRTYDAYCIG.1 |
AGE_YRS.1 + EDUC2.1 + GRADES.1,
dist = "negbin", na.action = na.omit, data = dat)
summary(zinb2)
# Zero-inflated negative binomial
library(pscl)
zinb2 <- zeroinfl(THIRTYDAYCIG.3 ~ STUDY_ARM + THIRTYDAYCIG.1 |
AGE_YRS.1 + EDUC2.1 + GRADES.1,
dist = "negbin", na.action = na.omit, data = dat)
fit.ZINB <-zeroinfl(THIRTYDAYCIG.3 ~ STUDY_ARM + THIRTYDAYCIG.1 |
AGE_YRS.1 + EDUC2.1 + GRADES.1,
dist = "negbin", na.action = na.omit, data = dat)
zinb2 <- zeroinfl(THIRTYDAYCIG.3 ~ STUDY_ARM + THIRTYDAYCIG.1 |
AGE_YRS.1 + EDUC2.1 + GRADES.1,
dist = "negbin", na.action = na.omit, data = dat)
fit.ZINB <-zeroinfl(THIRTYDAYCIG.3 ~ STUDY_ARM + THIRTYDAYCIG.1 |
THIRTYDAYCIB.1 + AGE_YRS.1 + EDUC2.1 + GRADES.1,
dist = "negbin", na.action = na.omit, data = dat)
fit.ZINB <-zeroinfl(THIRTYDAYCIG.3 ~ STUDY_ARM + THIRTYDAYCIG.1 |
THIRTYDAYCIG.1 + AGE_YRS.1 + EDUC2.1 + GRADES.1,
dist = "negbin", na.action = na.omit, data = dat)
zinb2 <- zeroinfl(THIRTYDAYCIG.3 ~ STUDY_ARM + THIRTYDAYCIG.1 |
AGE_YRS.1 + EDUC2.1 + GRADES.1,
dist = "negbin", na.action = na.omit, data = dat)
summary(zinb2)
# Does the negative binomial model fit significantly better
# as measured by likelihood-ratio test? NOTE: this test will
# not run unless you delete missing data from the start as follows:
dat <- na.omit(dat)
library(lmtest)
lrtest(glm1, nb1)
nb2 <- glm.nb(THIRTYDAYCIG.3 ~ STUDY_ARM + THIRTYDAYCIG.1,
control = glm.control(maxit = 1000),
na.action = na.omit, data = dat)
summary(nb2)
exp(-0.13)
exp(-0.89)
exp(0.34)
# Zero-inflated negative binomial
library(pscl)
fit.ZINB <-zeroinfl(THIRTYDAYCIG.3 ~ STUDY_ARM + THIRTYDAYCIG.1 |
THIRTYDAYCIG.1 + AGE_YRS.1 + EDUC2.1 + GRADES.1,
dist = "negbin", na.action = na.omit, data = dat)
zinb2 <- zeroinfl(THIRTYDAYCIG.3 ~ STUDY_ARM + THIRTYDAYCIG.1 |
AGE_YRS.1 + EDUC2.1 + GRADES.1,
dist = "negbin", na.action = na.omit, data = dat)
summary(zinb2)
vif(lm(THIRTYDAYCIG.3 ~ STUDY_ARM + THIRTYDAYCIG.1+ + AGE_YRS.1 + EDUC2.1 + GRADES.1, data= dat))
### Define aic & bic functions for use with ZINB models
bic <- function(fit){
pars <- fit$df.null - fit$df.residual + 2
n <- fit$n
lgLik <- logLik(fit)[1]
out <- -2 * lgLik + log(n) * pars
return (out)
}
aic <- function(fit){
pars <- fit$df.null - fit$df.residual + 2
n <- fit$n
lgLik <- logLik(fit)[1]
out <- -2 * lgLik + 2 * pars
return (out)
}
c(AIC(lm2), AIC(glm2), AIC(nb2), aic(zinb2))
fit.ZINB <-zeroinfl(THIRTYDAYCIG.3 ~ STUDY_ARM + THIRTYDAYCIG.1 |
THIRTYDAYCIG.1 + AGE_YRS.1 + EDUC2.1 + GRADES.1,
dist = "negbin", na.action = na.omit, data = dat)
zinb2 <- zeroinfl(THIRTYDAYCIG.3 ~ STUDY_ARM + THIRTYDAYCIG.1 |
AGE_YRS.1 + EDUC2.1 + GRADES.1,
dist = "negbin", na.action = na.omit, data = dat)
summary(zinb2)
vif(lm(THIRTYDAYCIG.3 ~ STUDY_ARM + THIRTYDAYCIG.1+ + AGE_YRS.1 + EDUC2.1 + GRADES.1, data= dat))
load("~/Desktop/Lab 8 my notes/Lab_08.Rdata")
# Load relevant packages. Install them first if needed.
library(car) # for qqPlot()
table(dat$THIRTYDAYCIG.3)
table(dat$STUDY_ARM, dat$THIRTYDAYCIG.3)
by(dat$THIRTYDAYCIG.3, dat$STUDY_ARM, mean, na.rm = TRUE)
# Examine missing data patterns
install.packages("mice")
library(mice)
?md.pattern
md.pattern(x = dat)
# Use t-test (Welch's version, not assuming equal
# group variances) for quantitative baseline variables.
t.test(x = dat$THIRTYDAYCIG.1[dat$STUDY_ARM == 0],
y = dat$THIRTYDAYCIG.1[dat$STUDY_ARM == 1],
alternative = "two.sided",
var.equal = FALSE)
library(car)
lm1 <- lm(THIRTYDAYCIG.3 ~ STUDY_ARM,
data = dat)
options(contrasts = c("contr.sum", "contr.poly"))
Anova(lm1, type = 3)
summary(lm1)
qqPlot(lm1) # Really bad!
cor(dat$THIRTYDAYCIG.1, dat$THIRTYDAYCIG.3, use = "complete.obs")
lm2 <- lm(THIRTYDAYCIG.3 ~ STUDY_ARM + THIRTYDAYCIG.1, data = dat)
Anova(lm2, type = 3)
summary(lm2)
qqPlot(lm2) # Really bad!
residualPlot(lm2) # Also bad!
mean(dat$THIRTYDAYCIG.3, na.rm = TRUE)
var(dat$THIRTYDAYCIG.3, na.rm = TRUE) # Yikes, big difference.
glm1 <- glm(THIRTYDAYCIG.3 ~ STUDY_ARM,
family = "poisson",
na.action = na.omit, data = dat)
summary(glm1)
glm2 <- glm(THIRTYDAYCIG.3 ~ STUDY_ARM + THIRTYDAYCIG.1,
family = "poisson",
na.action = na.omit, data = dat)
summary(glm2)
# Test for overdispersion. Null hypothesis is that Poisson
# assumption of equal mean and variance is true.
library(AER)
dispersiontest(glm1)
dispersiontest(glm2)
# Negative binomial model with no covariates.
library(MASS)
nb1 <- glm.nb(THIRTYDAYCIG.3 ~ STUDY_ARM,
na.action = na.omit, data = dat)
summary(nb1)
# Does the negative binomial model fit significantly better
# as measured by likelihood-ratio test? NOTE: this test will
# not run unless you delete missing data from the start as follows:
dat <- na.omit(dat)
library(lmtest)
lrtest(glm1, nb1)
nb2 <- glm.nb(THIRTYDAYCIG.3 ~ STUDY_ARM + THIRTYDAYCIG.1,
control = glm.control(maxit = 1000),
na.action = na.omit, data = dat)
summary(nb2)
# Zero-inflated negative binomial
library(pscl)
zinb2 <- zeroinfl(THIRTYDAYCIG.3 ~ STUDY_ARM + THIRTYDAYCIG.1 |
AGE_YRS.1 + EDUC2.1 + GRADES.1,
dist = "negbin", na.action = na.omit, data = dat)
summary(zinb2)
return (out)
### Define aic & bic functions for use with ZINB models
bic <- function(fit){
pars <- fit$df.null - fit$df.residual + 2
n <- fit$n
lgLik <- logLik(fit)[1]
out <- -2 * lgLik + log(n) * pars
return (out)
}
aic <- function(fit){
pars <- fit$df.null - fit$df.residual + 2
n <- fit$n
lgLik <- logLik(fit)[1]
out <- -2 * lgLik + 2 * pars
return (out)
}
c(AIC(lm2), AIC(glm2), AIC(nb2), aic(zinb2))
c(BIC(lm2), BIC(glm2), BIC(nb2), bic(zinb2))
summary(zinb2)
fisher.test(table(dat$STUDY_ARM, dat$AGE_YRS.1))
chisq.test(table(dat$STUDY_ARM, dat$EDUC2.1))
fisher.test(table(dat$STUDY_ARM, dat$GRADES.1))
zinb2 <- zeroinfl(THIRTYDAYCIG.3 ~ STUDY_ARM + THIRTYDAYCIG.1 |
EDUC2.1 + GRADES.1,
dist = "negbin", na.action = na.omit, data = dat)
summary(zinb2)
zinb2 <- zeroinfl(THIRTYDAYCIG.3 ~ STUDY_ARM + THIRTYDAYCIG.1 |
AGE_YRS.1 + GRADES.1,
dist = "negbin", na.action = na.omit, data = dat)
summary(zinb2)
zinb2 <- zeroinfl(THIRTYDAYCIG.3 ~ STUDY_ARM + THIRTYDAYCIG.1 |
AGE_YRS.1 + EDUC2.1,
dist = "negbin", na.action = na.omit, data = dat)
zinb2 <- zeroinfl(THIRTYDAYCIG.3 ~ STUDY_ARM + THIRTYDAYCIG.1 |
AGE_YRS.1 + EDUC2.1,
dist = "negbin", na.action = na.omit, data = dat)
### Define aic & bic functions for use with ZINB models
bic <- function(fit){
pars <- fit$df.null - fit$df.residual + 2
n <- fit$n
lgLik <- logLik(fit)[1]
out <- -2 * lgLik + log(n) * pars
return (out)
}
aic <- function(fit){
pars <- fit$df.null - fit$df.residual + 2
n <- fit$n
lgLik <- logLik(fit)[1]
out <- -2 * lgLik + 2 * pars
return (out)
}
fit.ZINB <-zeroinfl(THIRTYDAYCIG.3 ~ STUDY_ARM + THIRTYDAYCIG.1 |
THIRTYDAYCIG.1 + AGE_YRS.1 + EDUC2.1 + GRADES.1,
dist = "negbin", na.action = na.omit, data = dat)
zinb2 <- zeroinfl(THIRTYDAYCIG.3 ~ STUDY_ARM + THIRTYDAYCIG.1 |
AGE_YRS.1 + EDUC2.1 + GRADES.1,
dist = "negbin", na.action = na.omit, data = dat)
zinb2 <- zeroinfl(THIRTYDAYCIG.3 ~ STUDY_ARM + THIRTYDAYCIG.1 |
EDUC2.1 + GRADES.1,
dist = "negbin", na.action = na.omit, data = dat)
summary(zinb2)
### Define aic & bic functions for use with ZINB models
bic <- function(fit){
pars <- fit$df.null - fit$df.residual + 2
n <- fit$n
lgLik <- logLik(fit)[1]
out <- -2 * lgLik + log(n) * pars
return (out)
}
aic <- function(fit){
pars <- fit$df.null - fit$df.residual + 2
n <- fit$n
lgLik <- logLik(fit)[1]
out <- -2 * lgLik + 2 * pars
return (out)
}
c(AIC(lm2), AIC(glm2), AIC(nb2), aic(zinb2))
c(BIC(lm2), BIC(glm2), BIC(nb2), bic(zinb2))
zinb2 <- zeroinfl(THIRTYDAYCIG.2 ~ STUDY_ARM + THIRTYDAYCIG.1 +
AGE_YRS.1 + EDUC2.1 + GRADES.1,
dist = "negbin", na.action = na.omit, data = dat)
summary(zinb2)
### Define aic & bic functions for use with ZINB models
bic <- function(fit){
pars <- fit$df.null - fit$df.residual + 2
n <- fit$n
lgLik <- logLik(fit)[1]
out <- -2 * lgLik + log(n) * pars
return (out)
}
aic <- function(fit){
pars <- fit$df.null - fit$df.residual + 2
n <- fit$n
lgLik <- logLik(fit)[1]
out <- -2 * lgLik + 2 * pars
return (out)
}
c(AIC(lm2), AIC(glm2), AIC(nb2), aic(zinb2))
c(BIC(lm2), BIC(glm2), BIC(nb2), bic(zinb2))
###############
# Logistic and Multinomial Logistic Regression
###############
# Data for the logistic and multinomial logistic analyses
# come from the BEPS that we looked at in class.
# install.packages("EffectStars")
library(EffectStars)
data(BEPS) # load the data
?BEPS # Data description
head(BEPS)
str(BEPS)
table(BEPS$Vote, useNA = "ifany")
?BEPS # Data description
###############
# Logistic and Multinomial Logistic Regression
###############
# Data for the logistic and multinomial logistic analyses
# come from the BEPS that we looked at in class.
install.packages("EffectStars")
library(EffectStars)
data(BEPS) # load the data
?BEPS # Data description
head(BEPS)
str(BEPS)
table(BEPS$Vote, useNA = "ifany")
BEPS$Vote_d <- BEPS$Vote
BEPS$Vote_d[which(BEPS$Vote_d == "Labour")] <- NA
table(BEPS$Vote_d, useNA = "ifany")
str(BEPS)
# Run factor with Vote_d to drop the Labour level
BEPS$Vote_d <- factor(BEPS$Vote_d)
str(BEPS)
levels(BEPS$Vote_d) # Conservative is the reference category
table(dat$THIRTYDAYCIG.3)
table(dat$THIRTYDAYCIG.3)
table(dat$THIRTYDAYCIG.3)
# Lab 09 Task 1:
# Do your own analysis for THIRTYDAYCIG.3 and
# summarize your results.
exp(0.88)
# Lab 09 Task 1:
# Do your own analysis for THIRTYDAYCIG.3 and
# summarize your results.
exp(-0.21)
exp(-0.69)
exp(0.32)
BEPS$Vote_d <- BEPS$Vote
###############
# Logistic and Multinomial Logistic Regression
###############
# Data for the logistic and multinomial logistic analyses
# come from the BEPS that we looked at in class.
install.packages("EffectStars")
install.packages("EffectStars")
library(EffectStars)
data(BEPS) # load the data
?BEPS # Data description
head(BEPS)
str(BEPS)
table(BEPS$Vote, useNA = "ifany")
BEPS$Vote_d <- BEPS$Vote
BEPS$Vote_d[which(BEPS$Vote_d == "Labour")] <- NA
table(BEPS$Vote_d, useNA = "ifany")
str(BEPS)
# Run factor with Vote_d to drop the Labour level
BEPS$Vote_d <- factor(BEPS$Vote_d)
str(BEPS)
levels(BEPS$Vote_d) # Conservative is the reference category
# Logistic regression uses the glm function, which stands
# for "generalized linear model" and, since the outcome
# is dichotomous and we wish to fit a logistic model,
# we must specify family = "binomial".
glm1 <- glm(formula = Vote_d ~ Europe + Leader_Cons + Leader_Labour +
Leader_Liberals + Age + Gender + Political_Knowledge +
National_Economy + Household + Europe:Political_Knowledge,
data = BEPS, family = "binomial")
summary(glm1)
exp(-0.69)
# Coefficients:
coef(glm1)
# Exponentiated (and rounded) coefficients:
round(exp(coef(glm1)), 2)
exp(-0.71925163)
table(BEPS$Political_Knowledge)
# For multinomial logistic regression we will use package nnet.
install.packages("nnet")
library(nnet)
levels(BEPS$Vote)
mn1 <- multinom(formula = Vote ~ Europe + Leader_Cons + Leader_Labour +
Leader_Liberals + Age + Gender + Political_Knowledge +
National_Economy + Household + Europe:Political_Knowledge,
data = BEPS)
summary(mn1)
# Wald tests are used to test coefficients for significance
# based on the standard normal distribution. The Wald test
# statistic is the estimate divided by its SE. (this gives a p-value not the output)
(coeffs <- summary(mn1)$coefficients)
summary(mn1)
# Wald tests are used to test coefficients for significance
# based on the standard normal distribution. The Wald test
# statistic is the estimate divided by its SE. (this gives a p-value not the output)
(coeffs <- summary(mn1)$coefficients)
summary(glm1)
# Coefficients:
coef(glm1)
mn1 <- multinom(formula = Vote ~ Europe + Leader_Cons + Leader_Labour +
Leader_Liberals + Age + Gender + Political_Knowledge +
National_Economy + Household + Europe:Political_Knowledge,
data = BEPS)
summary(mn1)
# Wald tests are used to test coefficients for significance
# based on the standard normal distribution. The Wald test
# statistic is the estimate divided by its SE. (this gives a p-value not the output)
(coeffs <- summary(mn1)$coefficients)
(SEs <- summary(mn1)$standard.errors)
(walds <- coeffs/SEs)
(pvals <- 2*pnorm(abs(walds), lower.tail = FALSE))
round(pvals, 2)
# Exponentiated (and rounded) coefficients:
round(exp(coef(glm1)), 2)
round(exp(coeffs(mn1)), 2)
# Wald tests are used to test coefficients for significance
# based on the standard normal distribution. The Wald test
# statistic is the estimate divided by its SE. (this gives a p-value not the output)
(coeffs <- summary(mn1)$coefficients)
round(exp(coeffs(mn1)), 2)
exp(-0.87)
exp(coeffs(mn1)), 2
coef(mn1)
round(exp(coef(mn1)), 2)
(SEs <- summary(mn1)$standard.errors)
(walds <- coeffs/SEs)
(pvals <- 2*pnorm(abs(walds), lower.tail = FALSE))
round(pvals, 2)
0.42*1.93*0.85
0.42/(0.42*1.93*0.85)
# When PK = 0, (No political knowledge)
# Pr(Y = Dem | Covs)/[1 - Pr(Y = Dem | Covs)] = .53 * 3.17^0 * 1.04^E * .84^(0*E) * other stuff...
# Pr(Y = Dem | Covs)/[1 - Pr(Y = Dem | Covs)] = .53 * 1.04^E * other stuff... (new model)
# A one-unit incrase in Euroskepticism leads to a 4% increase in odds of
# identifying as a Liberal Democrat relative to identifying as a Conservative
0.53/1.41
0.49*(3.19^2)*(8.3^2)
1.07*0.83
# When PK = 0, (No political knowledge)
# Pr(Y = Dem | Covs)/[1 - Pr(Y = Dem | Covs)] = .53 * 3.17^0 * 1.04^E * .84^(0*E) * other stuff...
# Pr(Y = Dem | Covs)/[1 - Pr(Y = Dem | Covs)] = .53 * 1.04^E * other stuff... (new model)
# A one-unit incrase in Euroskepticism leads to a 4% increase in odds of
# identifying as a Liberal Democrat relative to identifying as a Conservative
0.53/1.41
0.42*1.93*0.85
.42*0.85^(0*1)
chrissy=read.csv("/Users/chrissycho/Desktop/FinalProjectVIF.csv")
round(cor(chrissy),2)
apa.cor.table(chrissy[,c(4:11, 13)], filename="CorrTable.doc", table.number = 2)
apa.cor.table(chrissy[,c(4:11, 13)], filename="CorrTable.doc", table.number = 1)
vif(chrissy)
library("car")
vif(chrissy)
install.packages("MASS")
library(MASS)
vif(chrissy)
load("~/Desktop/Data Analytics and Visualization Boot Camp/Unit assessment 1 & 2/house_data.csv")
x <- 3
numlist <-c(0,1,2,3,4,5,6,7,8,9)
setwd("~/Desktop/R_Analysis")
setwd("~/Desktop/R_Analysis")
NOTE
demo_table <- read.csv(file='demo.csv',check.names=F,stringsAsFactors = F)
demo_table <- read.csv("01_Demo/file=demo.csv",check.names=F,stringsAsFactors = F)
setwd("~/Desktop/R_Analysis/01_Demo")
demo_table <- read.csv(file='demo.csv',check.names=F,stringsAsFactors = F)
View(demo_table)
View(demo_table)
library(jsonlite)
library(jsonlite)
install.packages(jsonlite)
install.packages("tidyverse")
install.packages("jsonlite")
install.packages("jsonlite")
library("jsonlite")
library(jsonlite)
?fromJSON()
demo_table2 <- fromJSON(txt='demo.json')
View(demo_table2)
View(demo_table2)
> x[3]
> x <- c(3, 3, 2, 2, 5, 5, 8, 8, 9)
> x[3]
x <- c(3, 3, 2, 2, 5, 5, 8, 8, 9)
x[3]
demo_table[3, "Year"]
demo_table[3,3]
filter_table <- demo_table2[demo_table2$price > 10000,]
filter_table
View(filter_table)
View(filter_table)
?subset()
